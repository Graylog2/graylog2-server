# The auto-generated node ID will be stored in this file and read after restarts. It is a good idea
# to use an absolute file path here if you are starting graylog2-radio from init scripts or similar.
node_id_file = /etc/graylog2-radio-node-id

# Use AMQP ("amqp") or Kafka ("kafka") as message transport?
transport_type = amqp

# REST URI of a Graylog2 server node this radio will register at.
graylog2_server_uri = http://your-graylog2-server.example.org:12900/

# REST API listen URI. Must be reachable by the graylog2-web-interface and graylog2-server nodes.
rest_listen_uri = http://127.0.0.1:12950/

# REST API transport address. Defaults to the value of rest_listen_uri. Exception: If rest_listen_uri
# is set to a wildcard IP address (0.0.0.0) the first non-loopback IPv4 system address is used.
# This will be promoted in the cluster discovery APIs and other nodes may try to connect on this
# address. (see rest_listen_uri)
#rest_transport_uri = http://192.168.1.1:12950/

# ONLY FOR AMQP: Hostname of the AMQP broker to connect to.
amqp_broker_hostname = localhost

# ONLY FOR AMQP: Port of the AMQP broker to connect to.
amqp_broker_port = 5672

# ONLY FOR AMQP: Virtual host of the AMQP broker to connect to.
#amqp_broker_vhost = /

# ONLY FOR AMQP: Use a username to connect to the AMQP broker if you want.
#amqp_broker_username = user

# ONLY FOR AMQP: Use a password to connect to the AMQP broker if you want.
#amqp_broker_password = pass

# ONLY FOR KAFKA: One or more Kafka brokers. Radio will automatically use all brokers in that Kafka cluster but
# needs at least one to connect to initially.
#kafka_brokers = broker1.example.org:9092,broker2.example.org:9092

# ONLY FOR KAFKA: Send messages asynchronously in a background thread? By setting the producer to async we allow
# batching messages (which is great for throughput) but open the possibility of a failure of the
# client machine dropping unsent data. Set to either sync or async.
#kafka_producer_type = async

# ONLY FOR KAFKA: Only accounted when running in async mode. The size of messages batches to send at once. See
# also the kafka_batch_max_wait_ms parameter.
#kafka_batch_size = 200

# ONLY FOR KAFKA: Fow how many milliseconds to wait to reach the kafka_batch_size. The batch is sent to the broker
# no matter if the kafka_batch_size is reached or not. Think of this like a timeout for local
# buffering before sending.
#kafka_batch_max_wait_ms = 250

# ONLY FOR KAFKA: How many Kafka brokers must ack a message to consider it delivered. Can be set to 0 for a
# fast fire and forget approach.
#kafka_required_acks = 0

# The number of parallel running processors. Raise this number if your buffers are filling up.
processbuffer_processors = 5

# Wait strategy describing how buffer processors wait on a cursor sequence. (default: sleeping)
# Possible types:
#  - yielding
#     Compromise between performance and CPU usage.
#  - sleeping
#     Compromise between performance and CPU usage. Latency spikes can occur after quiet periods.
#  - blocking
#     High throughput, low latency, higher CPU usage.
#  - busy_spinning
#     Avoids syscalls which could introduce latency jitter. Best when threads can be bound to specific CPU cores.
processor_wait_strategy = blocking

# Size of internal ring buffers. Raise this if raising outputbuffer_processors does not help anymore.
# For optimum performance your LogMessage objects in the ring buffer should fit in your CPU L3 cache.
# Start server with --statistics flag to see buffer utilization.
# Must be a power of 2. (512, 1024, 2048, ...)
ring_size = 1024

# When more messages are coming in as we can process, incoming messages will be cached in memory until
# they are ready to be processed. Per default this data structure is unbounded, so in situations of
# constant high load, it will grow endlessly until all allocatable memory has been consumed and the
# process dies.
# To prevent this, the next setting allows you to define an upper bound for this memory cache, if the
# number of messages in the cache has reached this limit, incoming messages will be dropped until it
# has shrunk again.
#
# The default is 0, which means no upper bound.
#
#input_cache_max_size = 0
